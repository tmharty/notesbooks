{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.get_device_name(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Form-714-csv-files-June-2021/Part 3 Schedule 2 - Planning Area Hourly Demand.csv')\n",
    "respondent_id_info = pd.read_csv('./Form-714-csv-files-June-2021/Respondent IDs.csv')\n",
    "good_ids = respondent_id_info['respondent_id'].unique()[3:]\n",
    "df = df[df['respondent_id'].isin(good_ids)]\n",
    "hour_cols = [f'hour{i:02d}' for i in range(1, 25)]\n",
    "df = df.loc[~(df[hour_cols] == 0).any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_vae_data(df):\n",
    "    # Keep hourly columns as features\n",
    "    hour_cols = [f'hour{i:02d}' for i in range(1, 25)]\n",
    "    \n",
    "    # Convert date and extract features\n",
    "    df['plan_date'] = pd.to_datetime(df['plan_date'])\n",
    "    df['year'] = df['plan_date'].dt.year\n",
    "    df['month'] = df['plan_date'].dt.month\n",
    "    df['day_of_week'] = df['plan_date'].dt.dayofweek\n",
    "    \n",
    "    # Cyclic encoding for temporal features\n",
    "    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "    df['day_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
    "    df['day_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n",
    "    \n",
    "    # Normalize year\n",
    "    df['year'] = (df['year'] - df['year'].mean()) / df['year'].std()\n",
    "    \n",
    "    # Encode respondents\n",
    "    df['respondent_id'] = df['respondent_id'].astype('category')\n",
    "    df['respondent_idx'] = df['respondent_id'].cat.codes\n",
    "    df\n",
    "    # Normalize load values per respondent\n",
    "    for col in hour_cols:\n",
    "        df['og_' + col] = df[col].copy()\n",
    "        df[col] = df.groupby('respondent_id')[col].transform(\n",
    "            lambda x: (x - x.mean()) / x.std()\n",
    "        )\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE Dataset\n",
    "class VAEDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.loads = torch.FloatTensor(df[[f'hour{i:02d}' for i in range(1, 25)]].values)\n",
    "        self.respondents = torch.LongTensor(df['respondent_idx'].values)\n",
    "        self.temporal = torch.FloatTensor(df[['year', 'month_sin', 'month_cos', 'day_sin', 'day_cos']].values)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.loads)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.loads[idx], self.respondents[idx], self.temporal[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# VAE Model\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, num_respondents, temporal_dim=5, load_dim=24, \n",
    "                 embed_dim=32, hidden_dim=512, latent_dim=64):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embed = nn.Embedding(num_respondents, embed_dim)\n",
    "        self.temporal_dim = temporal_dim\n",
    "        self.load_dim = load_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(load_dim + embed_dim + temporal_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim//2, hidden_dim//4),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc_mu = nn.Linear(hidden_dim//4, self.latent_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_dim//4, self.latent_dim)\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(self.latent_dim + embed_dim + temporal_dim, hidden_dim//4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim//4, hidden_dim//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim//2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, load_dim)\n",
    "        )\n",
    "    \n",
    "    def encode(self, x, r, t):\n",
    "        embedded = self.embed(r)\n",
    "        combined = torch.cat([x, embedded, t], dim=1)\n",
    "        h = self.encoder(combined)\n",
    "        return self.fc_mu(h), self.fc_logvar(h)\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "    \n",
    "    def decode(self, z, r, t):\n",
    "        embedded = self.embed(r)\n",
    "        combined = torch.cat([z, embedded, t], dim=1)\n",
    "        return self.decoder(combined)\n",
    "    \n",
    "    def forward(self, x, r, t):\n",
    "        mu, logvar = self.encode(x, r, t)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z, r, t), mu, logvar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training Function\n",
    "def train_vae(df, num_epochs=50, batch_size=1_000_000, model=None):\n",
    "    df = prepare_vae_data(df)\n",
    "    dataset = VAEDataset(df)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    num_respondents = len(df['respondent_id'].cat.categories)\n",
    "    if model is None:\n",
    "        model = VAE(num_respondents)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print('device: ', device)\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for loads, respondents, temporal in loader:\n",
    "            optimizer.zero_grad()\n",
    "            loads = loads.to(device)\n",
    "            respondents = respondents.to(device)\n",
    "            temporal = temporal.to(device)\n",
    "            recon, mu, logvar = model(loads, respondents, temporal)\n",
    "            \n",
    "            # Reconstruction loss + KL divergence\n",
    "            recon_loss = nn.functional.mse_loss(recon, loads, reduction='sum')\n",
    "            kl_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "            \n",
    "            loss = recon_loss + kl_div\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        print(f'Epoch {epoch+1}, Loss: {train_loss/len(dataset):.4f}')\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_model = train_vae(df, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(vae_model.state_dict(), 'load_vae_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vae_model = VAE(num_respondents=len(df['respondent_id'].cat.categories))\n",
    "# vae_model.load_state_dict(torch.load('load_vae_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation and Visualization\n",
    "def generate_and_compare(model, df, respondent_id, date, n_samples=10):\n",
    "    # Prepare input\n",
    "    respondent_data = df[df['respondent_id'] == respondent_id]\n",
    "    sample = respondent_data[respondent_data['plan_date'] == date].iloc[0]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Get original data\n",
    "        original = torch.FloatTensor(sample[[f'hour{i:02d}' for i in range(1, 25)]]).unsqueeze(0)\n",
    "        respondent = torch.LongTensor([sample['respondent_idx']])\n",
    "        temporal = torch.FloatTensor(sample[['year', 'month_sin', 'month_cos', 'day_sin', 'day_cos']]).unsqueeze(0)\n",
    "        model.to('cpu')\n",
    "        \n",
    "        # Reconstruct\n",
    "        recon, _, _ = model(original, respondent, temporal)\n",
    "        \n",
    "        # Generate new samples\n",
    "        \n",
    "        z = torch.randn(n_samples, model.latent_dim)  # Generate 5 samples\n",
    "        \n",
    "        r = respondent.repeat(n_samples)\n",
    "        t = temporal.repeat(n_samples, 1)\n",
    "        generated = model.decode(z, r, t)\n",
    "    \n",
    "    # Denormalize\n",
    "    mean = respondent_data[[f'og_hour{i:02d}' for i in range(1, 25)]].mean().values # .mean()\n",
    "    std = respondent_data[[f'og_hour{i:02d}' for i in range(1, 25)]].std().values #.mean()\n",
    "    \n",
    "    original = original.squeeze().numpy() * std + mean\n",
    "    recon = recon.squeeze().numpy() * std + mean\n",
    "    generated = generated.numpy() * std + mean\n",
    "    \n",
    "    # Plot\n",
    "    hours = np.arange(24)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(hours, original, label='Original', linewidth=4)\n",
    "    plt.plot(hours, recon, '--', label='Reconstruction')\n",
    "    for i, gen in enumerate(generated):\n",
    "        plt.plot(hours, gen, alpha=0.5, color='k')# label=f'Generated Sample {i+1}')\n",
    "    \n",
    "    a_date = sample['plan_date']\n",
    "    a_year = a_date.year\n",
    "    year_buff = 3\n",
    "    a_doy = a_date.day_of_year\n",
    "    day_buff = 7\n",
    "    a_bool = np.logical_and(\n",
    "        np.abs(respondent_data['plan_date'].dt.year - a_year) <= year_buff,\n",
    "        np.abs(respondent_data['plan_date'].dt.day_of_year - a_doy) <= day_buff)\n",
    "    random_dates = np.random.choice(respondent_data['plan_date'].loc[a_bool], n_samples, replace=False)\n",
    "    for a_date in random_dates:\n",
    "        random_sample = respondent_data.loc[respondent_data['plan_date']==a_date]\n",
    "        random_sample = random_sample[[f'og_hour{i:02d}' for i in range(1, 25)]].values[0]\n",
    "        plt.plot(hours, random_sample, label=str(a_date)[:10])\n",
    "    \n",
    "    plt.title(f'Load Pattern for Respondent {respondent_id} on {date}')\n",
    "    plt.xlabel('Hour')\n",
    "    plt.ylabel('Load')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# respondent_id = np.random.choice(df['respondent_id'])\n",
    "respondent_id = 266\n",
    "respondent_data = df.loc[df['respondent_id']==respondent_id]\n",
    "date = str(np.random.choice(respondent_data['plan_date']))[:10]\n",
    "print(date)\n",
    "print(respondent_id)\n",
    "\n",
    "generate_and_compare(vae_model, df, \n",
    "                    respondent_id=respondent_id,  # Example respondent ID\n",
    "                    date=date)   # Example date"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
